# Fitness Classifier
### September, 2014

## Introduction
The goal of this project is to predict the manner in which participants perform fitness exercises using raw accelerator data collected from devices such as belt, forearm, arm, and dumbell of the participants. There are five classifications for how the exercises are performed.  The classifications are identified by A, B, C, D, and E.  

In this analysis, a machine learning model algorithm is built using a cross validated training data and out of sample error rate is calculated. Additional validation is performed using a separate test data set that is provided.

The data for this project is downloaded from http://groupware.les.inf.puc-rio.br/har

## Load Data

First download the training and testing data files and read them in as csv files.

```{r, warning=FALSE,message=FALSE,prompt=FALSE}
library(caret); 
library(randomForest); 

# load data files
if(!file.exists("trainData.csv")) 
{
  download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", 
                destfile= "./trainData.csv")
}

if(!file.exists("testData.csv")) 
{
  download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", 
                destfile= "./testData.csv")
}

trainData = read.csv("trainData.csv", na.strings = c('NA','#DIV/0!',''), stringsAsFactors=FALSE)
testData  = read.csv("testData.csv",  na.strings = c('NA','#DIV/0!',''), stringsAsFactors=FALSE )
```

## Data Processing and Feature Selection

In order to reduce unnecessary complexity of the model, irrelevant or erroneous features are dropped from the data set.  

In the data set, select data items with the feature new_window == "no", which indicates that it is a sensor reading and not statistical derivations of the reading.

```{r}
trainData = trainData[trainData$new_window == "no", ]
```

Next, select features that have high variance in the data set.  Using <code>nearZeroVar()</code> features with very low variance are identified and the corresponding columns are noted to ignore.
```{r}
nZeroVar      = nearZeroVar(trainData, saveMetrics=TRUE)
ignoreColumns = row.names(nZeroVar[nZeroVar$nzv==TRUE, ])
```

Additionally, data features which have no intrinsic value to the experiment are identified.  They are "X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", and "num_window".  These columns do not quantify how the participants are performing the exercises.
```{r}
ignoreColumns = append(ignoreColumns, c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "num_window"))
```

The data columns that are identified to ignore are dropped from both training data and the testing data.  
```{r}
trainData = trainData[, -which(names(trainData) %in% ignoreColumns)]
testData  = testData[, -which(names(testData) %in% ignoreColumns)]
trainData$classe <-as.factor(trainData$classe)
```


## Data Slicing and Cross Validation

```{r}
dim(trainData)
```

In order to cross validate, training data is sliced into two subsets: train subset and test subset. 
This is done to get an idea of what is the out of sample error in the model before the validation with final test data set.
Since training data set can be qualify as a low to medium sized data set, using the rules of thumb for prediction study design as describe in the class lecture, 60% of training data is partition for training and 40% for the testing.

```{r}
set.seed(643216)
inTrain <- createDataPartition (y= trainData$classe, p=0.6, list = FALSE)
trainData.training = trainData[inTrain,]
trainData.testing  = trainData[-inTrain,]
```

The size of the train and test subsets are as follows:
```{r}
dim(trainData.training)
dim(trainData.testing)
```



## Model Building

Random Forrest machine learning algorithm is selected as the model to train the data because the algorithm is known to be very accurate and has bootstrap capability. In order to save the computational time, <code>trainControl()</code> is used to set the number of cross validation to 3.  

```{r}
trainCtrl = trainControl(method = "cv", number = 3)

if (file.exists("rf.model")) {
  load( "rf.model" )
} else {
  modelRf <- train(classe~., method="rf", trControl=trainCtrl, data=trainData.training, prox=TRUE) 
  save(file="rf.model", "modelRf")
}
```

Training test subset is used to predict results and get estimate out of sample error rate.  Using the <code>confusionMatrix</code>, accuracy measure of the prediction is obtained.  The estimate for out of sample error rate is defined as <code>1-Accuracy</code>.

```{r}
p = predict(modelRf, trainData.testing)
cm = confusionMatrix(p, trainData.testing$classe)
cm
```


Therefore, the out of sample error rate is `r 1-cm$overall[1]`.


## Test Data Validation

Using the provided test data, the following are the result of prediction.

```{r}
test.predict = predict(modelRf, testData)
test.predict
```


